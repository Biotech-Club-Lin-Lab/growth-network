{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db689266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm # For progress bars during evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f3c0e",
   "metadata": {},
   "source": [
    "### Chromosome\n",
    "This section defines the Chromosome class, which represents a neural network's structure and parameters. It handles node and edge management, network operations (like forward pass), structural mutations such as node division, and visualization. It also contains an inner class for running the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dacbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module defines the Chromosome class, which represents a neural network's\n",
    "structure and parameters for neuroevolutionary algorithms. It handles node and\n",
    "edge management, network operations, structural mutations like node division,\n",
    "and visualization. It also contains an inner class for running the neural network.\n",
    "\"\"\"\n",
    "\n",
    "class Chromosome:\n",
    "    \"\"\"\n",
    "    Represents a neural network chromosome, encapsulating its nodes, edges,\n",
    "    and methods for genetic operations and network execution.\n",
    "\n",
    "    A chromosome's structure is defined by two Pandas DataFrames:\n",
    "    - `nodes`: Stores information about each neuron (ID, type, bias, birth generation, division count).\n",
    "    - `edges`: Stores information about connections between neurons (ID, source, target, weight, enabled status).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        id: int,\n",
    "        nodes_df: pd.DataFrame = None,\n",
    "        edges_df: pd.DataFrame = None,\n",
    "        inputs: int = None,\n",
    "        outputs: int = None,\n",
    "        hidden_nodes: int = None,  # Number of hidden nodes to create if starting from scratch\n",
    "        connectivity_ratio: float = 0.5,  # Ratio of possible connections to create for initial network\n",
    "        generation: int = 0,       # Track the generation of this chromosome\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Chromosome instance.\n",
    "\n",
    "        Can initialize with pre-existing node and edge DataFrames, or create a\n",
    "        new, randomly structured network based on specified input/output/hidden\n",
    "        node counts and connectivity ratio.\n",
    "\n",
    "        Args:\n",
    "            id (int): Unique identifier for this chromosome.\n",
    "            nodes_df (pd.DataFrame, optional): DataFrame containing node data.\n",
    "                If provided, `edges_df` must also be provided. Defaults to None.\n",
    "            edges_df (pd.DataFrame, optional): DataFrame containing edge data.\n",
    "                If provided, `nodes_df` must also be provided. Defaults to None.\n",
    "            inputs (int, optional): Number of input nodes to create. Required if\n",
    "                `nodes_df` and `edges_df` are None.\n",
    "            outputs (int, optional): Number of output nodes to create. Required if\n",
    "                `nodes_df` and `edges_df` are None.\n",
    "            hidden_nodes (int, optional): Initial number of hidden nodes to create.\n",
    "                Defaults to 10 if not specified and creating a new network.\n",
    "            connectivity_ratio (float, optional): Density of initial connections.\n",
    "                A ratio of 0.5 means roughly half of possible connections between\n",
    "                layers (input-hidden, hidden-output, hidden-hidden) will be made.\n",
    "                Defaults to 0.5.\n",
    "            generation (int, optional): The generation this chromosome was created in.\n",
    "                Defaults to 0.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `nodes_df` is provided but `edges_df` is not, or vice-versa.\n",
    "            ValueError: If creating a new network and `inputs` or `outputs` are not provided.\n",
    "        \"\"\"\n",
    "        self.id = id\n",
    "        self.generation = generation\n",
    "\n",
    "        if nodes_df is None and edges_df is None:\n",
    "            if inputs is None or outputs is None:\n",
    "                raise ValueError(\"Inputs and outputs must be specified when creating a new chromosome.\")\n",
    "\n",
    "            self.nodes = pd.DataFrame(columns=['id', 'type', 'bias', 'birth_generation', 'division_count'])\n",
    "            self.edges = pd.DataFrame(columns=['id', 'source', 'target', 'weight', 'enabled'])\n",
    "\n",
    "            if connectivity_ratio is None:\n",
    "                connectivity_ratio = 0.5\n",
    "            \n",
    "            # Default hidden_nodes if not specified\n",
    "            if hidden_nodes is None:\n",
    "                hidden_nodes = 10\n",
    "\n",
    "            node_count = 0\n",
    "            edge_count = 0\n",
    "\n",
    "            # Create input nodes\n",
    "            input_start_id = node_count\n",
    "            for i in range(inputs):\n",
    "                self.nodes.loc[node_count] = {\n",
    "                    'id': node_count,\n",
    "                    'type': 'input',\n",
    "                    'bias': 0.0,  # Input nodes typically don't have bias\n",
    "                    'birth_generation': generation,\n",
    "                    'division_count': 0\n",
    "                }\n",
    "                node_count += 1\n",
    "\n",
    "            # Create hidden nodes\n",
    "            hidden_start_id = node_count\n",
    "            for h in range(hidden_nodes):\n",
    "                self.nodes.loc[node_count] = {\n",
    "                    'id': node_count,\n",
    "                    'type': 'hidden',\n",
    "                    'bias': np.random.uniform(-1, 1),\n",
    "                    'birth_generation': generation,\n",
    "                    'division_count': 0\n",
    "                }\n",
    "                node_count += 1\n",
    "\n",
    "            # Create output nodes\n",
    "            output_start_id = node_count\n",
    "            for o in range(outputs):\n",
    "                self.nodes.loc[node_count] = {\n",
    "                    'id': node_count,\n",
    "                    'type': 'output',\n",
    "                    'bias': np.random.uniform(-1, 1),\n",
    "                    'birth_generation': generation,\n",
    "                    'division_count': 0\n",
    "                }\n",
    "                node_count += 1\n",
    "\n",
    "            input_ids = list(range(input_start_id, hidden_start_id))\n",
    "            hidden_ids = list(range(hidden_start_id, output_start_id))\n",
    "            output_ids = list(range(output_start_id, node_count))\n",
    "            \n",
    "            # Helper for initial network creation (local scope)\n",
    "            def _would_create_cycle_initial(source, target, existing_edges_df):\n",
    "                \"\"\"Check if adding edge would create a cycle in a temporary graph.\"\"\"\n",
    "                G_temp = nx.DiGraph()\n",
    "                for _, edge_row in existing_edges_df.iterrows():\n",
    "                    if edge_row['enabled']:\n",
    "                        G_temp.add_edge(edge_row['source'], edge_row['target'])\n",
    "                G_temp.add_edge(source, target)\n",
    "                try:\n",
    "                    nx.find_cycle(G_temp)\n",
    "                    return True\n",
    "                except nx.NetworkXNoCycle:\n",
    "                    return False\n",
    "\n",
    "            # Connect inputs to some hidden nodes\n",
    "            if hidden_ids: # Ensure there are hidden nodes to connect to\n",
    "                for i in input_ids:\n",
    "                    num_connections = max(1, int(connectivity_ratio * len(hidden_ids)))\n",
    "                    targets = random.sample(hidden_ids, min(num_connections, len(hidden_ids))) # Ensure not to sample more than available\n",
    "                    for t in targets:\n",
    "                        self.edges.loc[edge_count] = {\n",
    "                            'id': edge_count,\n",
    "                            'source': i,\n",
    "                            'target': t,\n",
    "                            'weight': np.random.uniform(-1, 1),\n",
    "                            'enabled': True\n",
    "                        }\n",
    "                        edge_count += 1\n",
    "\n",
    "            # Connect hidden nodes to output nodes\n",
    "            if hidden_ids and output_ids: # Ensure both hidden and output nodes exist\n",
    "                for h in hidden_ids:\n",
    "                    num_connections = max(1, int(connectivity_ratio * len(output_ids)))\n",
    "                    targets = random.sample(output_ids, min(num_connections, len(output_ids)))\n",
    "                    for t in targets:\n",
    "                        self.edges.loc[edge_count] = {\n",
    "                            'id': edge_count,\n",
    "                            'source': h,\n",
    "                            'target': t,\n",
    "                            'weight': np.random.uniform(-1, 1),\n",
    "                            'enabled': True\n",
    "                        }\n",
    "                        edge_count += 1\n",
    "            elif not hidden_ids and input_ids and output_ids: # Direct input to output if no hidden nodes\n",
    "                for i in input_ids:\n",
    "                    num_connections = max(1, int(connectivity_ratio * len(output_ids)))\n",
    "                    targets = random.sample(output_ids, min(num_connections, len(output_ids)))\n",
    "                    for t in targets:\n",
    "                         self.edges.loc[edge_count] = {\n",
    "                            'id': edge_count,\n",
    "                            'source': i,\n",
    "                            'target': t,\n",
    "                            'weight': np.random.uniform(-1, 1),\n",
    "                            'enabled': True\n",
    "                        }\n",
    "                         edge_count += 1\n",
    "\n",
    "            # Add some additional hidden-to-hidden connections\n",
    "            if len(hidden_ids) > 1:\n",
    "                possible_h2h = [(src, tgt) for src in hidden_ids for tgt in hidden_ids if src != tgt]\n",
    "                random.shuffle(possible_h2h)\n",
    "                \n",
    "                # Limit connections to avoid excessively dense networks\n",
    "                num_h2h_to_try = int(connectivity_ratio * len(possible_h2h))\n",
    "                \n",
    "                for src, tgt in possible_h2h[:num_h2h_to_try]:\n",
    "                    # Create a temporary DataFrame to test cycle prevention with current edges\n",
    "                    temp_edges_for_cycle_check = self.edges.copy()\n",
    "                    if not _would_create_cycle_initial(src, tgt, temp_edges_for_cycle_check):\n",
    "                        self.edges.loc[edge_count] = {\n",
    "                            'id': edge_count,\n",
    "                            'source': src,\n",
    "                            'target': tgt,\n",
    "                            'weight': np.random.uniform(-1, 1),\n",
    "                            'enabled': True\n",
    "                        }\n",
    "                        edge_count += 1\n",
    "        elif nodes_df is not None and edges_df is not None:\n",
    "            self.nodes = nodes_df.copy()\n",
    "            self.edges = edges_df.copy()\n",
    "        else:\n",
    "            raise ValueError(\"Both nodes_df and edges_df must be provided, or neither.\")\n",
    "        \n",
    "        # Initialize the NN instance for running the network\n",
    "        self.NN = self.NeuralNetwork(self)\n",
    "    \n",
    "    # Node-related methods\n",
    "    def get_node_by_id(self, node_id: int) -> pd.Series | None:\n",
    "        \"\"\"\n",
    "        Retrieves a node by its unique identifier.\n",
    "\n",
    "        Args:\n",
    "            node_id (int): The ID of the node to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series or None: A Pandas Series representing the node if found, otherwise None.\n",
    "        \"\"\"\n",
    "        result = self.nodes[self.nodes['id'] == node_id]\n",
    "        return result.iloc[0] if not result.empty else None\n",
    "    \n",
    "    def get_nodes_by_type(self, node_type: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all nodes of a specific type.\n",
    "\n",
    "        Args:\n",
    "            node_type (str): The type of node to filter by (e.g., 'input', 'hidden', 'output').\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all nodes of the specified type.\n",
    "        \"\"\"\n",
    "        return self.nodes[self.nodes['type'] == node_type]\n",
    "    \n",
    "    def get_input_nodes(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all input nodes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all input nodes.\n",
    "        \"\"\"\n",
    "        return self.get_nodes_by_type('input')\n",
    "    \n",
    "    def get_output_nodes(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all output nodes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all output nodes.\n",
    "        \"\"\"\n",
    "        return self.get_nodes_by_type('output')\n",
    "    \n",
    "    def get_hidden_nodes(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all hidden nodes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all hidden nodes.\n",
    "        \"\"\"\n",
    "        return self.get_nodes_by_type('hidden')\n",
    "    \n",
    "    # Edge-related methods\n",
    "    def get_edge_by_id(self, edge_id: int) -> pd.Series | None:\n",
    "        \"\"\"\n",
    "        Retrieves an edge by its unique identifier.\n",
    "\n",
    "        Args:\n",
    "            edge_id (int): The ID of the edge to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series or None: A Pandas Series representing the edge if found, otherwise None.\n",
    "        \"\"\"\n",
    "        result = self.edges[self.edges['id'] == edge_id]\n",
    "        return result.iloc[0] if not result.empty else None\n",
    "    \n",
    "    def get_edges_by_source(self, source_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all edges originating from a specific source node.\n",
    "\n",
    "        Args:\n",
    "            source_id (int): The ID of the source node.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all outgoing edges from the source node.\n",
    "        \"\"\"\n",
    "        return self.edges[self.edges['source'] == source_id]\n",
    "    \n",
    "    def get_edges_by_target(self, target_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all edges terminating at a specific target node.\n",
    "\n",
    "        Args:\n",
    "            target_id (int): The ID of the target node.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all incoming edges to the target node.\n",
    "        \"\"\"\n",
    "        return self.edges[self.edges['target'] == target_id]\n",
    "    \n",
    "    def get_edges_between(self, source_id: int, target_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all edges connecting a specific source node to a specific target node.\n",
    "\n",
    "        Args:\n",
    "            source_id (int): The ID of the source node.\n",
    "            target_id (int): The ID of the target node.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing edges between the specified source and target.\n",
    "        \"\"\"\n",
    "        mask = (self.edges['source'] == source_id) & (self.edges['target'] == target_id)\n",
    "        return self.edges[mask]\n",
    "    \n",
    "    def get_enabled_edges(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all enabled edges in the network.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing all enabled edges.\n",
    "        \"\"\"\n",
    "        return self.edges[self.edges['enabled'] == True]\n",
    "    \n",
    "    def would_create_cycle(self, source: int, target: int) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if adding an edge from a source node to a target node would create a cycle\n",
    "        in the current network's enabled connections.\n",
    "\n",
    "        Args:\n",
    "            source (int): The ID of the source node for the proposed edge.\n",
    "            target (int): The ID of the target node for the proposed edge.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if adding the edge would create a cycle, False otherwise.\n",
    "        \"\"\"\n",
    "        G = nx.DiGraph()\n",
    "        for _, edge in self.edges.iterrows():\n",
    "            if edge['enabled']:\n",
    "                G.add_edge(edge['source'], edge['target'])\n",
    "        \n",
    "        G.add_edge(source, target) # Temporarily add the proposed edge for cycle check\n",
    "        \n",
    "        try:\n",
    "            nx.find_cycle(G)\n",
    "            return True  # Found a cycle\n",
    "        except nx.NetworkXNoCycle:\n",
    "            return False  # No cycle found\n",
    "            \n",
    "    # Network modification operations\n",
    "    def add_node(self, node_type: str, bias: float = None, birth_generation: int = None) -> int:\n",
    "        \"\"\"\n",
    "        Adds a new node to the network.\n",
    "\n",
    "        The new node ID is automatically determined as the next available integer.\n",
    "        Bias is initialized randomly for hidden/output nodes if not provided, and 0.0 for input nodes.\n",
    "\n",
    "        Args:\n",
    "            node_type (str): The type of the node ('input', 'hidden', 'output').\n",
    "            bias (float, optional): The bias value for the new node. If None, it's\n",
    "                                    randomly generated (or 0 for input nodes). Defaults to None.\n",
    "            birth_generation (int, optional): The generation in which this node was created.\n",
    "                                            If None, uses the chromosome's current generation. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            int: The ID of the newly created node.\n",
    "        \"\"\"\n",
    "        # Get new node_id\n",
    "        new_node_id = int(self.nodes['id'].max() + 1) if not self.nodes.empty else 0\n",
    "        \n",
    "        # Set bias based on node type\n",
    "        if bias is None:\n",
    "            if node_type == 'input':\n",
    "                bias = 0.0\n",
    "            else:\n",
    "                bias = np.random.uniform(-1, 1)\n",
    "        \n",
    "        # If birth_generation not provided, use current generation\n",
    "        if birth_generation is None:\n",
    "            birth_generation = self.generation\n",
    "        \n",
    "        new_node_data = {\n",
    "            'id': new_node_id,\n",
    "            'type': node_type,\n",
    "            'bias': bias,\n",
    "            'birth_generation': birth_generation,\n",
    "            'division_count': 0\n",
    "        }\n",
    "        \n",
    "        # Append to nodes DataFrame\n",
    "        # Using pd.concat for immutability and better practices in Pandas\n",
    "        self.nodes = pd.concat([self.nodes, pd.DataFrame([new_node_data])], ignore_index=True)\n",
    "        \n",
    "        return new_node_id\n",
    "    \n",
    "    def add_edge(self, source: int, target: int, weight: float = None, enabled: bool = True) -> int | None:\n",
    "        \"\"\"\n",
    "        Adds a new edge to the network, preventing cycles.\n",
    "\n",
    "        If the edge would create a cycle with existing enabled edges, it is not added.\n",
    "        Weight is generated randomly if not provided.\n",
    "\n",
    "        Args:\n",
    "            source (int): The ID of the source node.\n",
    "            target (int): The ID of the target node.\n",
    "            weight (float, optional): The weight of the new edge. If None, it's\n",
    "                                    randomly generated. Defaults to None.\n",
    "            enabled (bool, optional): Whether the edge is initially enabled. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            int or None: The ID of the newly created edge if added, None if it would create a cycle.\n",
    "        \"\"\"\n",
    "        # Check if adding this edge would create a cycle\n",
    "        if self.would_create_cycle(source, target):\n",
    "            return None\n",
    "            \n",
    "        # Generate weight if not provided\n",
    "        if weight is None:\n",
    "            weight = np.random.uniform(-1, 1)\n",
    "        \n",
    "        # Get new edge_id\n",
    "        new_edge_id = int(self.edges['id'].max() + 1) if not self.edges.empty else 0\n",
    "        \n",
    "        new_edge_data = {\n",
    "            'id': new_edge_id,\n",
    "            'source': source,\n",
    "            'target': target,\n",
    "            'weight': weight,\n",
    "            'enabled': enabled\n",
    "        }\n",
    "        \n",
    "        # Append to edges DataFrame\n",
    "        self.edges = pd.concat([self.edges, pd.DataFrame([new_edge_data])], ignore_index=True)\n",
    "        \n",
    "        return new_edge_id\n",
    "    \n",
    "    def disable_edge(self, edge_id: int) -> bool:\n",
    "        \"\"\"\n",
    "        Disables an existing edge by setting its 'enabled' status to False.\n",
    "\n",
    "        Args:\n",
    "            edge_id (int): The ID of the edge to disable.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the edge was found and disabled, False otherwise.\n",
    "        \"\"\"\n",
    "        idx = self.edges.index[self.edges['id'] == edge_id].tolist()\n",
    "        if idx:\n",
    "            self.edges.loc[idx[0], 'enabled'] = False\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def update_node_bias(self, node_id: int, new_bias: float) -> bool:\n",
    "        \"\"\"\n",
    "        Updates the bias of a specific node.\n",
    "\n",
    "        Args:\n",
    "            node_id (int): The ID of the node whose bias is to be updated.\n",
    "            new_bias (float): The new bias value.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the node was found and updated, False otherwise.\n",
    "        \"\"\"\n",
    "        idx = self.nodes.index[self.nodes['id'] == node_id].tolist()\n",
    "        if idx:\n",
    "            self.nodes.loc[idx[0], 'bias'] = new_bias\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def update_edge_weight(self, edge_id: int, new_weight: float) -> bool:\n",
    "        \"\"\"\n",
    "        Updates the weight of a specific edge.\n",
    "\n",
    "        Args:\n",
    "            edge_id (int): The ID of the edge whose weight is to be updated.\n",
    "            new_weight (float): The new weight value.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the edge was found and updated, False otherwise.\n",
    "        \"\"\"\n",
    "        idx = self.edges.index[self.edges['id'] == edge_id].tolist()\n",
    "        if idx:\n",
    "            self.edges.loc[idx[0], 'weight'] = new_weight\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_connection_count(self, node_id: int) -> int:\n",
    "        \"\"\"\n",
    "        Calculates the total number of incoming and outgoing connections for a given node.\n",
    "\n",
    "        Args:\n",
    "            node_id (int): The ID of the node.\n",
    "\n",
    "        Returns:\n",
    "            int: The sum of incoming and outgoing connections for the node.\n",
    "        \"\"\"\n",
    "        incoming = len(self.get_edges_by_target(node_id))\n",
    "        outgoing = len(self.get_edges_by_source(node_id))\n",
    "        return incoming + outgoing\n",
    "        \n",
    "    # Node Division (Structural Mutation) methods\n",
    "    def evaluate_division(self, node_id: int, division_model: 'Chromosome') -> bool:\n",
    "        \"\"\"\n",
    "        Evaluates whether a hidden node should divide based on inputs to a separate\n",
    "        neural network (the `division_model`). Adds randomness to introduce variability.\n",
    "\n",
    "        This method is designed to be used with a `division_model` that has 4 inputs:\n",
    "        [normalized_age, normalized_division_count, normalized_connection_count, normalized_node_id].\n",
    "        Its single output determines the division probability.\n",
    "\n",
    "        Args:\n",
    "            node_id (int): The ID of the node to evaluate for division.\n",
    "            division_model (Chromosome): A separate Chromosome instance acting as a\n",
    "                                         neural network to make the division decision.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the node should divide, False otherwise.\n",
    "        \"\"\"\n",
    "        node = self.get_node_by_id(node_id)\n",
    "        \n",
    "        if node is None or node['type'] != 'hidden':\n",
    "            return False # Only hidden nodes can divide\n",
    "        \n",
    "        node_age = self.generation - node['birth_generation']\n",
    "        division_count = node['division_count']\n",
    "        connection_count = self.get_connection_count(node_id)\n",
    "        \n",
    "        # Arbitrary maximum values for normalization\n",
    "        max_age = 20\n",
    "        max_division = 5\n",
    "        max_connections = 20\n",
    "        # Determine max_node_id dynamically to scale better with network growth\n",
    "        max_node_id = self.nodes['id'].max() + 1 if not self.nodes.empty else 100 \n",
    "        \n",
    "        normalized_age = node_age / max_age\n",
    "        normalized_division = division_count / max_division\n",
    "        normalized_connections = connection_count / max_connections\n",
    "        normalized_node_id = node_id / max_node_id\n",
    "        \n",
    "        # Add random noise to inputs to create variability\n",
    "        noise_range = 0.3\n",
    "        noisy_age = normalized_age + random.uniform(-noise_range, noise_range)\n",
    "        noisy_division = normalized_division + random.uniform(-noise_range, noise_range)\n",
    "        noisy_connections = normalized_connections + random.uniform(-noise_range, noise_range)\n",
    "        noisy_node_id = normalized_node_id + random.uniform(-noise_range, noise_range)\n",
    "        \n",
    "        inputs_for_division_model = [noisy_age, noisy_division, noisy_connections, noisy_node_id]\n",
    "        output_from_model = division_model.NN.run(inputs_for_division_model)\n",
    "        \n",
    "        # Add node-specific randomness to the output\n",
    "        node_specific_factor = random.uniform(0.7, 1.3)\n",
    "        modified_output = output_from_model[0] * node_specific_factor\n",
    "        \n",
    "        # Use a random threshold for the decision\n",
    "        threshold = random.uniform(0.2, 0.5)\n",
    "        \n",
    "        return modified_output > threshold\n",
    "    \n",
    "    def perform_division(self, node_id: int, bias_func=None) -> list[int]:\n",
    "        \"\"\"\n",
    "        Performs the division of a single hidden node.\n",
    "        A new \"daughter\" node is created, and connections are established.\n",
    "        The parent node's division count is incremented.\n",
    "\n",
    "        Args:\n",
    "            node_id (int): The ID of the parent node to divide.\n",
    "            bias_func (callable, optional): A function that takes the parent's bias\n",
    "                                           and returns the daughter's bias. If None,\n",
    "                                           a default random variation is used. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: A list containing the ID of the newly created daughter node.\n",
    "                       Returns an empty list if the parent node is not hidden.\n",
    "        \"\"\"\n",
    "        parent_node = self.get_node_by_id(node_id)\n",
    "        \n",
    "        if parent_node is None or parent_node['type'] != 'hidden':\n",
    "            return []\n",
    "        \n",
    "        # Increment division count of parent node\n",
    "        parent_idx = self.nodes.index[self.nodes['id'] == node_id].tolist()[0]\n",
    "        self.nodes.at[parent_idx, 'division_count'] += 1\n",
    "        \n",
    "        # Default bias function: random variation of parent bias\n",
    "        if bias_func is None:\n",
    "            bias_func = lambda p_bias: p_bias + np.random.uniform(-0.2, 0.2)\n",
    "        \n",
    "        # Create a daughter node of the same type ('hidden')\n",
    "        daughter_id = self.add_node(\n",
    "            node_type='hidden',\n",
    "            bias=bias_func(parent_node['bias']),\n",
    "            birth_generation=self.generation\n",
    "        )\n",
    "        \n",
    "        # Connect parent to daughter if it doesn't create a cycle\n",
    "        if daughter_id is not None and not self.would_create_cycle(node_id, daughter_id):\n",
    "            self.add_edge(source=node_id, target=daughter_id)\n",
    "        \n",
    "        # Connect incoming edges to daughter (replicate parent's incoming connections)\n",
    "        for _, edge in self.get_edges_by_target(node_id).iterrows():\n",
    "            # Skip self-loops and connections from parent (to avoid creating loops)\n",
    "            if edge['source'] != node_id and edge['source'] != daughter_id:\n",
    "                if not self.would_create_cycle(edge['source'], daughter_id):\n",
    "                    self.add_edge(source=edge['source'], target=daughter_id, weight=edge['weight'])\n",
    "        \n",
    "        # Connect daughter to outgoing edges (replicate parent's outgoing connections)\n",
    "        for _, edge in self.get_edges_by_source(node_id).iterrows():\n",
    "            # Skip self-loops and connections to parent (to avoid creating loops)\n",
    "            if edge['target'] != node_id and edge['target'] != daughter_id:\n",
    "                if not self.would_create_cycle(daughter_id, edge['target']):\n",
    "                    self.add_edge(source=daughter_id, target=edge['target'], weight=edge['weight'])\n",
    "        \n",
    "        return [daughter_id] if daughter_id is not None else []\n",
    "    \n",
    "    def evaluate_all_nodes_for_division(self, division_model: 'Chromosome', bias_func=None) -> list[int]:\n",
    "        \"\"\"\n",
    "        Evaluates all hidden nodes in the chromosome for division and performs the division\n",
    "        if the criteria set by the `division_model` are met.\n",
    "\n",
    "        Args:\n",
    "            division_model (Chromosome): A Chromosome instance that acts as the decision model\n",
    "                                         for node division.\n",
    "            bias_func (callable, optional): Function to calculate the bias of daughter nodes.\n",
    "                                           If None, a default is used. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: A list of IDs of all newly created nodes during this process.\n",
    "        \"\"\"\n",
    "        hidden_nodes = self.get_hidden_nodes()\n",
    "        new_nodes = []\n",
    "        \n",
    "        # Make a copy of node IDs to avoid iteration issues when adding nodes\n",
    "        nodes_to_evaluate = hidden_nodes['id'].tolist()\n",
    "        \n",
    "        for node_id in nodes_to_evaluate:\n",
    "            # Check if node_id still exists after previous divisions (important if new nodes are added)\n",
    "            # This handles cases where a node might be a newly divided node itself and should not divide again immediately\n",
    "            if node_id in self.nodes['id'].values and self.get_node_by_id(node_id)['type'] == 'hidden':\n",
    "                if self.evaluate_division(node_id, division_model):\n",
    "                    daughter_nodes = self.perform_division(node_id, bias_func)\n",
    "                    new_nodes.extend(daughter_nodes)\n",
    "        \n",
    "        return new_nodes\n",
    "    \n",
    "    # Visualization methods\n",
    "    def to_networkx(self) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Converts the chromosome's network structure into a NetworkX directed graph object.\n",
    "        This is useful for graph analysis and visualization.\n",
    "\n",
    "        Returns:\n",
    "            nx.DiGraph: A NetworkX directed graph representing the chromosome.\n",
    "        \"\"\"\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes with their attributes\n",
    "        for _, node in self.nodes.iterrows():\n",
    "            G.add_node(\n",
    "                node['id'], \n",
    "                type=node['type'],\n",
    "                bias=node['bias'],\n",
    "                birth_generation=node['birth_generation'],\n",
    "                division_count=node['division_count']\n",
    "            )\n",
    "        \n",
    "        # Add enabled edges with their attributes\n",
    "        for _, edge in self.edges.iterrows():\n",
    "            if edge['enabled']:\n",
    "                G.add_edge(\n",
    "                    edge['source'],\n",
    "                    edge['target'],\n",
    "                    weight=edge['weight'],\n",
    "                    id=edge['id']\n",
    "                )\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def visualize(self, ax=None, figsize: tuple[int, int] = (10, 8)):\n",
    "        \"\"\"\n",
    "        Visualizes the neural network structure using NetworkX and Matplotlib.\n",
    "\n",
    "        Nodes are colored based on their type (input, hidden, output).\n",
    "        Edges are colored based on weight sign (green for positive, red for negative)\n",
    "        and width is proportional to absolute weight.\n",
    "\n",
    "        Args:\n",
    "            ax (matplotlib.axes.Axes, optional): A Matplotlib axes object to draw on.\n",
    "                                                If None, a new figure and axes are created.\n",
    "                                                Defaults to None.\n",
    "            figsize (tuple[int, int], optional): Dimensions of the figure if `ax` is None.\n",
    "                                               Defaults to (10, 8).\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.axes.Axes: The Matplotlib axes object the graph was drawn on.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        G = self.to_networkx()\n",
    "        \n",
    "        # Use a hierarchical layout (e.g., 'dot' from Graphviz) if available, otherwise fall back\n",
    "        try:\n",
    "            pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "        except ImportError:\n",
    "            # Fall back to spring layout if graphviz/pygraphviz is not installed\n",
    "            print(\"Graphviz not found. Falling back to spring layout for visualization. For better layouts, install graphviz and pygraphviz.\")\n",
    "            pos = nx.spring_layout(G, k=0.8, iterations=50) # Increased k for more spread, more iterations for stability\n",
    "        \n",
    "        # Draw nodes by type with different colors\n",
    "        node_colors = []\n",
    "        for node_id in G.nodes():\n",
    "            node_type = G.nodes[node_id]['type']\n",
    "            if node_type == 'input':\n",
    "                node_colors.append('lightblue')\n",
    "            elif node_type == 'hidden':\n",
    "                node_colors.append('lightgreen')  \n",
    "            elif node_type == 'output':\n",
    "                node_colors.append('lightcoral')\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, ax=ax, node_color=node_colors, node_size=700, alpha=0.9) # Slightly larger nodes\n",
    "        \n",
    "        edge_colors = []\n",
    "        edge_widths = []\n",
    "        \n",
    "        for u, v, data in G.edges(data=True):\n",
    "            weight = data['weight']\n",
    "            edge_colors.append('green' if weight >= 0 else 'red') # Green for positive, red for negative\n",
    "            edge_widths.append(abs(weight) * 2 + 0.5) # Minimum width for visibility\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, ax=ax, edge_color=edge_colors, width=edge_widths, \n",
    "                               arrowsize=15, connectionstyle='arc3,rad=0.1', alpha=0.7)\n",
    "        \n",
    "        # Draw node labels (node IDs)\n",
    "        node_labels = {node_id: node_id for node_id in G.nodes()}\n",
    "        nx.draw_networkx_labels(G, pos, ax=ax, labels=node_labels, font_size=9, font_weight='bold')\n",
    "\n",
    "        # Draw edge labels (weights) for enabled edges\n",
    "        edge_labels = {\n",
    "            (u, v): f\"{data['weight']:.2f}\"\n",
    "            for u, v, data in G.edges(data=True) if data.get('enabled', True)\n",
    "        }\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, ax=ax, font_size=7, bbox={\"alpha\": 0.7, \"pad\": 0.5})\n",
    "        \n",
    "        if ax is None: # Only set title/axis if a new figure was created\n",
    "            plt.title(f\"Chromosome {self.id} Network Structure\", size=14)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    class NeuralNetwork:\n",
    "        \"\"\"\n",
    "        An inner class representing the executable neural network defined by the Chromosome's\n",
    "        nodes and edges. Handles the forward pass computation.\n",
    "        \"\"\"\n",
    "        def __init__(self, chromosome_instance: 'Chromosome'):\n",
    "            \"\"\"\n",
    "            Initializes the NeuralNetwork executor.\n",
    "\n",
    "            Args:\n",
    "                chromosome_instance (Chromosome): The parent Chromosome instance whose\n",
    "                                                  nodes and edges define this network.\n",
    "            \"\"\"\n",
    "            self.edges = chromosome_instance.edges\n",
    "            self.nodes = chromosome_instance.nodes\n",
    "            self.results = pd.DataFrame({'node id': self.nodes['id'].values, 'result': None})\n",
    "        \n",
    "        def run(self, X: np.ndarray | list) -> list[float]:\n",
    "            \"\"\"\n",
    "            Performs a forward pass through the neural network given an input array.\n",
    "\n",
    "            This method topologically sorts the graph for efficient execution,\n",
    "            computes node activations using ReLU, and returns the outputs of\n",
    "            the output nodes. Handles cycles by falling back to a default order.\n",
    "\n",
    "            Args:\n",
    "                X (np.ndarray | list): The input values for the input nodes.\n",
    "                                      Must match the number of input nodes.\n",
    "\n",
    "            Returns:\n",
    "                list[float]: A list of activation values for the output nodes.\n",
    "                             Any uncomputed output node results will be 0.0.\n",
    "\n",
    "            Raises:\n",
    "                ValueError: If the input array `X` does not match the number of input nodes.\n",
    "            \"\"\"\n",
    "            # Reset results for a new run\n",
    "            self.results['result'] = None\n",
    "\n",
    "            inp_ids = self.nodes.loc[self.nodes['type'] == 'input', 'id'].values\n",
    "            \n",
    "            if len(X) != len(inp_ids):\n",
    "                raise ValueError(f\"Input size {len(X)} doesn't match network input nodes {len(inp_ids)}\")\n",
    "                \n",
    "            # Set input values in the results DataFrame\n",
    "            for i, val in enumerate(X):\n",
    "                self.results.loc[self.results['node id'] == inp_ids[i], 'result'] = val\n",
    "            \n",
    "            # Create a directed graph for topological sort\n",
    "            G_run = nx.DiGraph()\n",
    "            for _, edge in self.edges.iterrows():\n",
    "                if edge['enabled']:\n",
    "                    G_run.add_edge(edge['source'], edge['target'])\n",
    "            \n",
    "            execution_order = []\n",
    "            try:\n",
    "                # Get execution order through topological sort\n",
    "                execution_order = list(nx.topological_sort(G_run))\n",
    "                # Filter out input nodes as their values are already set\n",
    "                execution_order = [node_id for node_id in execution_order \n",
    "                                   if node_id not in inp_ids]\n",
    "            except nx.NetworkXUnfeasible:\n",
    "                # If there's a cycle, fall back to default order (e.g., node ID order for non-inputs)\n",
    "                # This might not process nodes in the 'correct' order for cyclic graphs,\n",
    "                # but prevents crashes and allows the network to still attempt computation.\n",
    "                print(\"Warning: Cycle detected in network. Falling back to default execution order.\")\n",
    "                execution_order = self.nodes.loc[~self.nodes['id'].isin(inp_ids), 'id'].values\n",
    "            \n",
    "            def ReLU(x: float) -> float:\n",
    "                \"\"\"Rectified Linear Unit activation function.\"\"\"\n",
    "                return np.maximum(0, x)\n",
    "            \n",
    "            # Execute nodes in order\n",
    "            for node_id in execution_order:\n",
    "                # Only process nodes if all their necessary inputs are computed\n",
    "                incoming_edges = self.edges.loc[(self.edges['target'] == node_id) & (self.edges['enabled'] == True)]\n",
    "                \n",
    "                if incoming_edges.empty:\n",
    "                    # If a node has no incoming edges (and is not an input), its value remains None or 0.0\n",
    "                    # This handles isolated hidden/output nodes, or nodes that are targets of only disabled edges.\n",
    "                    continue\n",
    "\n",
    "                source_node_ids = incoming_edges['source'].values\n",
    "                # Get results for source nodes that have already been computed\n",
    "                source_vals_df = self.results.loc[self.results['node id'].isin(source_node_ids)]\n",
    "                \n",
    "                # Check if all required source node values are available (not None/NaN)\n",
    "                if not source_vals_df.empty and not source_vals_df['result'].isnull().any():\n",
    "                    # Align weights with source values\n",
    "                    # Create a mapping from source_id to its computed result\n",
    "                    source_results_map = source_vals_df.set_index('node id')['result'].to_dict()\n",
    "                    \n",
    "                    # Ensure weights are aligned with the order of source_values\n",
    "                    # Filter incoming edges to only those whose source results are available\n",
    "                    valid_incoming_edges = incoming_edges[incoming_edges['source'].isin(source_results_map.keys())]\n",
    "\n",
    "                    if not valid_incoming_edges.empty:\n",
    "                        # Extract weights in the order corresponding to source_node_ids\n",
    "                        # Ensure 'source' column is used for indexing for correct alignment\n",
    "                        weights_aligned = valid_incoming_edges.set_index('source').loc[list(source_results_map.keys())]['weight'].values\n",
    "                        x_values = np.array(list(source_results_map.values()))\n",
    "                        \n",
    "                        b = self.nodes.loc[self.nodes['id'] == node_id, 'bias'].values[0]\n",
    "                        \n",
    "                        # Dot product of inputs (x) and weights (w) plus bias\n",
    "                        output = ReLU(np.dot(x_values, weights_aligned) + b)\n",
    "                        self.results.loc[self.results['node id'] == node_id, 'result'] = output\n",
    "            \n",
    "            # Extract and return output values\n",
    "            output_node_ids = self.nodes.loc[self.nodes['type'] == 'output', 'id'].values\n",
    "            outputs = self.results.loc[self.results['node id'].isin(output_node_ids), 'result'].values\n",
    "            \n",
    "            # Convert to list and replace None/NaN values with 0.0 for consistency\n",
    "            final_outputs = [0.0 if v is None or pd.isna(v) else float(v) for v in outputs]\n",
    "            return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f297e",
   "metadata": {},
   "source": [
    "### Evolution\n",
    "\n",
    "This section defines the Evolution class, which orchestrates the evolutionary process for optimizing neural network chromosomes. It includes methods for fitness evaluation (using the CartPole environment), genetic operators (selection, crossover, mutation), and tracking evolutionary progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module defines the Evolution class, which orchestrates the evolutionary\n",
    "process for optimizing neural network chromosomes, typically applied to\n",
    "reinforcement learning tasks like CartPole. It includes methods for fitness\n",
    "evaluation, genetic operators (selection, crossover, mutation), and tracking\n",
    "evolutionary progress.\n",
    "\"\"\"\n",
    "\n",
    "class Evolution:\n",
    "    \"\"\"\n",
    "    Manages the evolutionary algorithm, including population generation,\n",
    "    fitness evaluation, parent selection, crossover, and mutation to evolve\n",
    "    neural network chromosomes.\n",
    "    \"\"\"\n",
    "    def __init__(self, population_size: int = 20, inputs: int = 4, outputs: int = 1, hidden_nodes: int = 15, connectivity_ratio: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initializes the evolutionary process parameters and creates the initial population.\n",
    "\n",
    "        Args:\n",
    "            population_size (int, optional): Number of chromosomes in each generation. Defaults to 20.\n",
    "            inputs (int, optional): Number of input nodes for each neural network in the population. Defaults to 4.\n",
    "            outputs (int, optional): Number of output nodes for each neural network in the population. Defaults to 1.\n",
    "            hidden_nodes (int, optional): Initial number of hidden nodes for newly created chromosomes. Defaults to 15.\n",
    "            connectivity_ratio (float, optional): Initial density of connections for new chromosomes. Defaults to 0.5.\n",
    "        \"\"\"\n",
    "        self.population_size = population_size\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.connectivity_ratio = connectivity_ratio\n",
    "        self.generation = 0\n",
    "        self.population: list[Chromosome] = []\n",
    "        self.best_fitness = -float('inf') # Initialize with negative infinity\n",
    "        self.best_chromosome: Chromosome | None = None\n",
    "        self.fitness_history: list[dict] = []\n",
    "        \n",
    "        # Create initial population\n",
    "        for i in range(self.population_size):\n",
    "            chromosome = Chromosome(\n",
    "                id=i,\n",
    "                inputs=self.inputs,\n",
    "                outputs=self.outputs,\n",
    "                hidden_nodes=self.hidden_nodes,\n",
    "                connectivity_ratio=self.connectivity_ratio,\n",
    "                generation=self.generation\n",
    "            )\n",
    "            self.population.append(chromosome)\n",
    "    \n",
    "    def _validate_network(self, chromosome: Chromosome) -> bool:\n",
    "        \"\"\"\n",
    "        Validates the structure of a neural network chromosome.\n",
    "\n",
    "        Checks for basic validity like:\n",
    "        - All input nodes having at least one outgoing connection.\n",
    "        - The network being runnable with the expected input size.\n",
    "\n",
    "        Args:\n",
    "            chromosome (Chromosome): The chromosome to validate.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the network structure is considered valid, False otherwise.\n",
    "        \"\"\"\n",
    "        input_nodes = chromosome.get_input_nodes()['id'].values\n",
    "        \n",
    "        if len(input_nodes) != self.inputs:\n",
    "            print(f\"Validation Error: Chromosome {chromosome.id} has {len(input_nodes)} input nodes, expected {self.inputs}.\")\n",
    "            return False\n",
    "\n",
    "        for input_id in input_nodes:\n",
    "            if chromosome.get_edges_by_source(input_id).empty:\n",
    "                print(f\"Validation Error: Input node {input_id} in chromosome {chromosome.id} has no outgoing connections.\")\n",
    "                return False\n",
    "                \n",
    "        # Check network can handle expected input size by running a dummy input\n",
    "        try:\n",
    "            test_input = np.zeros(self.inputs)\n",
    "            chromosome.NN.run(test_input)\n",
    "            return True\n",
    "        except ValueError as e:\n",
    "            print(f\"Network validation failed for chromosome {chromosome.id} due to input size mismatch: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Network validation failed for chromosome {chromosome.id} due to runtime error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def evaluate_fitness(self, chromosome: Chromosome, render: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Evaluates the fitness of a chromosome by running it in the CartPole-v1 environment.\n",
    "        The fitness score is the total reward accumulated during an episode.\n",
    "\n",
    "        Args:\n",
    "            chromosome (Chromosome): The chromosome (neural network) to evaluate.\n",
    "            render (bool, optional): If True, the environment will be rendered visually. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            float: The total reward (fitness score) achieved in the CartPole environment.\n",
    "        \"\"\"\n",
    "        # A network with invalid structure gets minimum fitness\n",
    "        if not self._validate_network(chromosome):\n",
    "            # print(f\"Warning: Invalid network structure in chromosome {chromosome.id}, returning fitness 0.\")\n",
    "            return 0.0 # Return minimum fitness for invalid networks\n",
    "        \n",
    "        # Initialize the CartPole environment\n",
    "        env = gym.make('CartPole-v1', render_mode='human' if render else None)\n",
    "        observation, _ = env.reset()\n",
    "        \n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        max_steps = 500  # Maximum episode length for CartPole-v1\n",
    "        \n",
    "        while not done and total_reward < max_steps:\n",
    "            # Use neural network to determine action\n",
    "            action = self._get_action(chromosome, observation)\n",
    "            \n",
    "            # Take step in environment\n",
    "            observation, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "        \n",
    "        env.close()\n",
    "        return float(total_reward)\n",
    "    \n",
    "    def _get_action(self, chromosome: Chromosome, observation: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        Determines the action to take in the environment using the neural network.\n",
    "\n",
    "        For CartPole, the observation values are already in a reasonable range,\n",
    "        so no explicit normalization is applied here. The network's single\n",
    "        output is thresholded to 0 or 1.\n",
    "\n",
    "        Args:\n",
    "            chromosome (Chromosome): The neural network chromosome.\n",
    "            observation (np.ndarray): The current state observation from the environment.\n",
    "\n",
    "        Returns:\n",
    "            int: The chosen action (0 for left, 1 for right).\n",
    "        \"\"\"\n",
    "        # CartPole observation values are typically small, direct use often works\n",
    "        # If necessary, further normalization could be added here (e.g., scaling to -1 to 1)\n",
    "        norm_obs = observation.astype(float) # Ensure float type for NN\n",
    "\n",
    "        output = chromosome.NN.run(norm_obs)\n",
    "        \n",
    "        # Convert output to discrete action (0 or 1)\n",
    "        # Assuming a single output node for binary classification\n",
    "        if output: # Check if output list is not empty\n",
    "            return 1 if output[0] > 0.5 else 0\n",
    "        return 0 # Default action if network somehow produces no output\n",
    "    \n",
    "    def evaluate_population(self) -> list[tuple[Chromosome, float]]:\n",
    "        \"\"\"\n",
    "        Evaluates the fitness of every chromosome in the current population.\n",
    "        Sorts the population by fitness in descending order and updates the\n",
    "        overall best chromosome and fitness history.\n",
    "\n",
    "        Returns:\n",
    "            list[tuple[Chromosome, float]]: A list of (chromosome, fitness) tuples,\n",
    "                                            sorted by fitness from highest to lowest.\n",
    "        \"\"\"\n",
    "        fitness_scores = []\n",
    "        \n",
    "        # Use tqdm for a progress bar during evaluation\n",
    "        for chromosome in tqdm(self.population, desc=f\"Generation {self.generation}\"):\n",
    "            fitness = self.evaluate_fitness(chromosome)\n",
    "            fitness_scores.append((chromosome, fitness))\n",
    "            \n",
    "        # Sort by fitness (descending)\n",
    "        fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Update best chromosome if a new best is found\n",
    "        if fitness_scores[0][1] > self.best_fitness:\n",
    "            self.best_fitness = fitness_scores[0][1]\n",
    "            self.best_chromosome = fitness_scores[0][0]\n",
    "        \n",
    "        # Record average and max fitness for history tracking\n",
    "        avg_fitness = sum(score for _, score in fitness_scores) / len(fitness_scores)\n",
    "        self.fitness_history.append({\n",
    "            'generation': self.generation,\n",
    "            'max_fitness': fitness_scores[0][1],\n",
    "            'avg_fitness': avg_fitness\n",
    "        })\n",
    "        \n",
    "        return fitness_scores\n",
    "    \n",
    "    def select_parents(self, fitness_scores: list[tuple[Chromosome, float]], selection_method: str = 'tournament', tournament_size: int = 3) -> list[Chromosome]:\n",
    "        \"\"\"\n",
    "        Selects parent chromosomes from the population based on their fitness.\n",
    "\n",
    "        Args:\n",
    "            fitness_scores (list[tuple[Chromosome, float]]): A list of (chromosome, fitness) tuples.\n",
    "                                                            Expected to be sorted by fitness.\n",
    "            selection_method (str, optional): The method to use for selection ('tournament' or 'roulette').\n",
    "                                              Defaults to 'tournament'.\n",
    "            tournament_size (int, optional): Number of individuals in each tournament (for 'tournament' method).\n",
    "                                             Defaults to 3.\n",
    "\n",
    "        Returns:\n",
    "            list[Chromosome]: A list of selected parent chromosomes, typically `self.population_size` in length.\n",
    "        \"\"\"\n",
    "        parents = []\n",
    "        \n",
    "        if selection_method == 'tournament':\n",
    "            for _ in range(self.population_size):\n",
    "                # Ensure tournament_size doesn't exceed available population\n",
    "                actual_tournament_size = min(tournament_size, len(fitness_scores))\n",
    "                if actual_tournament_size == 0: # Handle empty fitness_scores\n",
    "                    break\n",
    "                tournament = random.sample(fitness_scores, actual_tournament_size)\n",
    "                winner = max(tournament, key=lambda x: x[1])\n",
    "                parents.append(winner[0])\n",
    "                \n",
    "        elif selection_method == 'roulette':\n",
    "            total_fitness = sum(score for _, score in fitness_scores)\n",
    "            \n",
    "            # Handle cases where all fitnesses are zero or negative\n",
    "            if total_fitness <= 0: # If all are zero or negative, give equal chance, or pick best\n",
    "                # Assign small positive fitness to all if total_fitness is 0 or negative\n",
    "                # to allow selection. Or, more simply, just pick randomly or elite.\n",
    "                if len(fitness_scores) > 0:\n",
    "                    # If all fitness is zero, pick randomly. If negative, might still be relative.\n",
    "                    # For robust roulette, all fitnesses should be non-negative.\n",
    "                    # Add a small offset if all are zero to ensure pickability.\n",
    "                    min_fitness = min(score for _, score in fitness_scores) if fitness_scores else 0\n",
    "                    if min_fitness < 0:\n",
    "                        adjusted_scores = [(chrom, score - min_fitness + 1) for chrom, score in fitness_scores]\n",
    "                        total_fitness = sum(score for _, score in adjusted_scores)\n",
    "                    elif total_fitness == 0 and len(fitness_scores) > 0:\n",
    "                        adjusted_scores = [(chrom, 1) for chrom, _ in fitness_scores]\n",
    "                        total_fitness = len(fitness_scores)\n",
    "                    else:\n",
    "                        adjusted_scores = fitness_scores # Should not happen if total_fitness <= 0 but also > 0\n",
    "                else:\n",
    "                    return [] # No parents if no fitness scores\n",
    "            else:\n",
    "                adjusted_scores = fitness_scores\n",
    "\n",
    "            for _ in range(self.population_size):\n",
    "                pick = random.uniform(0, total_fitness)\n",
    "                current = 0\n",
    "                for chromosome, score in adjusted_scores:\n",
    "                    current += score\n",
    "                    if current > pick:\n",
    "                        parents.append(chromosome)\n",
    "                        break\n",
    "                # Fallback in case floating point issues or an edge case\n",
    "                if not parents or len(parents) < _ + 1:\n",
    "                    parents.append(fitness_scores[0][0]) # Add the best if selection fails\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown selection method: {selection_method}\")\n",
    "        \n",
    "        return parents\n",
    "    \n",
    "    def crossover(self, parent1: Chromosome, parent2: Chromosome) -> Chromosome:\n",
    "        \"\"\"\n",
    "        Performs crossover between two parent chromosomes to create a child chromosome.\n",
    "        The crossover strategy combines nodes and edges from both parents.\n",
    "        Prioritizes combining edges based on target nodes.\n",
    "\n",
    "        Args:\n",
    "            parent1 (Chromosome): The first parent chromosome.\n",
    "            parent2 (Chromosome): The second parent chromosome.\n",
    "\n",
    "        Returns:\n",
    "            Chromosome: A new child chromosome resulting from the crossover.\n",
    "        \"\"\"\n",
    "        all_nodes_list = []\n",
    "        # Start with all nodes from parent1\n",
    "        all_nodes_list.extend(parent1.nodes.to_dict('records'))\n",
    "        \n",
    "        # Add nodes from parent2 that are not in parent1\n",
    "        parent1_node_ids = set(parent1.nodes['id'].values)\n",
    "        for _, node_row in parent2.nodes.iterrows():\n",
    "            if node_row['id'] not in parent1_node_ids:\n",
    "                all_nodes_list.append(node_row.to_dict())\n",
    "\n",
    "        # Create a combined node DataFrame, ensure unique IDs after copying (especially new nodes from parent2)\n",
    "        combined_nodes_df = pd.DataFrame(all_nodes_list).drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "\n",
    "        # Re-index node IDs to be contiguous and start from 0 for the child\n",
    "        # This is crucial for keeping node IDs consistent and avoiding huge sparse IDs.\n",
    "        # Create a mapping from old ID to new ID\n",
    "        old_to_new_node_id_map = {old_id: new_id for new_id, old_id in enumerate(combined_nodes_df['id'].unique())}\n",
    "        combined_nodes_df['id'] = combined_nodes_df['id'].map(old_to_new_node_id_map)\n",
    "\n",
    "        edge_records = []\n",
    "        \n",
    "        # Group edges by target node for easier handling\n",
    "        p1_edges_by_target = parent1.edges.copy().groupby('target')\n",
    "        p2_edges_by_target = parent2.edges.copy().groupby('target')\n",
    "        \n",
    "        # Get all target nodes from both parents, and map them to new IDs\n",
    "        all_targets_old_ids = set(parent1.edges['target'].unique()) | set(parent2.edges['target'].unique())\n",
    "        all_targets_new_ids = {old_to_new_node_id_map.get(old_id, old_id) for old_id in all_targets_old_ids} # Handle case where target node might not have been in combined_nodes_df\n",
    "\n",
    "        # For each target node, randomly choose which parent's incoming edges to use\n",
    "        # or combine them carefully\n",
    "        for old_target_id in all_targets_old_ids:\n",
    "            new_target_id = old_to_new_node_id_map.get(old_target_id, old_target_id)\n",
    "            \n",
    "            # Simple choice: 50/50 probability to pick parent's edges for this target\n",
    "            chosen_parent = random.choice([1, 2])\n",
    "\n",
    "            source_edges_to_add = pd.DataFrame(columns=parent1.edges.columns) # Temporary DF\n",
    "            \n",
    "            if chosen_parent == 1 and old_target_id in p1_edges_by_target.groups:\n",
    "                source_edges_to_add = pd.concat([source_edges_to_add, p1_edges_by_target.get_group(old_target_id)])\n",
    "            elif chosen_parent == 2 and old_target_id in p2_edges_by_target.groups:\n",
    "                source_edges_to_add = pd.concat([source_edges_to_add, p2_edges_by_target.get_group(old_target_id)])\n",
    "\n",
    "            for _, edge in source_edges_to_add.iterrows():\n",
    "                new_source_id = old_to_new_node_id_map.get(edge['source'], edge['source'])\n",
    "                \n",
    "                # Check if the source node exists in the child's new combined_nodes_df\n",
    "                # This should prevent adding edges to non-existent nodes in the child.\n",
    "                if new_source_id in combined_nodes_df['id'].values and new_target_id in combined_nodes_df['id'].values:\n",
    "                    edge_records.append({\n",
    "                        'source': new_source_id,\n",
    "                        'target': new_target_id,\n",
    "                        'weight': edge['weight'],\n",
    "                        'enabled': edge['enabled']\n",
    "                    })\n",
    "        \n",
    "        # Create child edges DataFrame, dropping duplicates based on (source, target) pairs\n",
    "        child_edges_df = pd.DataFrame(edge_records).drop_duplicates(subset=['source', 'target']).reset_index(drop=True)\n",
    "        # Assign new sequential IDs to edges\n",
    "        child_edges_df['id'] = range(len(child_edges_df))\n",
    "\n",
    "        # Ensure essential nodes (inputs/outputs) exist and are connected\n",
    "        # Input nodes check\n",
    "        child_input_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'input']['id'].values\n",
    "        for expected_input_idx in range(self.inputs):\n",
    "            # Check if we have enough input nodes. If not, add dummy ones or from parents (if available).\n",
    "            if expected_input_idx >= len(child_input_nodes_ids):\n",
    "                # Find an input node from parents that hasn't been added yet\n",
    "                candidate_input_nodes_p1 = parent1.get_input_nodes().sort_values('id').iloc[expected_input_idx - len(child_input_nodes_ids):]\n",
    "                candidate_input_nodes_p2 = parent2.get_input_nodes().sort_values('id').iloc[expected_input_idx - len(child_input_nodes_ids):]\n",
    "                \n",
    "                new_input_node_data = None\n",
    "                if not candidate_input_nodes_p1.empty:\n",
    "                    new_input_node_data = candidate_input_nodes_p1.iloc[0].to_dict()\n",
    "                elif not candidate_input_nodes_p2.empty:\n",
    "                    new_input_node_data = candidate_input_nodes_p2.iloc[0].to_dict()\n",
    "                \n",
    "                if new_input_node_data:\n",
    "                    # Map old ID to new ID, or assign a truly new one\n",
    "                    new_input_node_data['id'] = old_to_new_node_id_map.get(new_input_node_data['id'], combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0)\n",
    "                    if new_input_node_data['id'] in combined_nodes_df['id'].values: # If ID clashes, find next available\n",
    "                         new_input_node_data['id'] = combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0\n",
    "\n",
    "                    combined_nodes_df = pd.concat([combined_nodes_df, pd.DataFrame([new_input_node_data])], ignore_index=True)\n",
    "                    child_input_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'input']['id'].values # Refresh list\n",
    "                else:\n",
    "                    # If no candidate, add a completely new input node\n",
    "                    new_input_id = combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0\n",
    "                    new_input_node_data = {'id': new_input_id, 'type': 'input', 'bias': 0.0, 'birth_generation': self.generation + 1, 'division_count': 0}\n",
    "                    combined_nodes_df = pd.concat([combined_nodes_df, pd.DataFrame([new_input_node_data])], ignore_index=True)\n",
    "                    child_input_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'input']['id'].values # Refresh list\n",
    "\n",
    "        # Output nodes check (similar logic to input nodes)\n",
    "        child_output_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'output']['id'].values\n",
    "        for expected_output_idx in range(self.outputs):\n",
    "            if expected_output_idx >= len(child_output_nodes_ids):\n",
    "                candidate_output_nodes_p1 = parent1.get_output_nodes().sort_values('id').iloc[expected_output_idx - len(child_output_nodes_ids):]\n",
    "                candidate_output_nodes_p2 = parent2.get_output_nodes().sort_values('id').iloc[expected_output_idx - len(child_output_nodes_ids):]\n",
    "                \n",
    "                new_output_node_data = None\n",
    "                if not candidate_output_nodes_p1.empty:\n",
    "                    new_output_node_data = candidate_output_nodes_p1.iloc[0].to_dict()\n",
    "                elif not candidate_output_nodes_p2.empty:\n",
    "                    new_output_node_data = candidate_output_nodes_p2.iloc[0].to_dict()\n",
    "\n",
    "                if new_output_node_data:\n",
    "                    new_output_node_data['id'] = old_to_new_node_id_map.get(new_output_node_data['id'], combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0)\n",
    "                    if new_output_node_data['id'] in combined_nodes_df['id'].values:\n",
    "                         new_output_node_data['id'] = combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0\n",
    "                    combined_nodes_df = pd.concat([combined_nodes_df, pd.DataFrame([new_output_node_data])], ignore_index=True)\n",
    "                    child_output_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'output']['id'].values # Refresh list\n",
    "                else:\n",
    "                    new_output_id = combined_nodes_df['id'].max() + 1 if not combined_nodes_df.empty else 0\n",
    "                    new_output_node_data = {'id': new_output_id, 'type': 'output', 'bias': np.random.uniform(-1, 1), 'birth_generation': self.generation + 1, 'division_count': 0}\n",
    "                    combined_nodes_df = pd.concat([combined_nodes_df, pd.DataFrame([new_output_node_data])], ignore_index=True)\n",
    "                    child_output_nodes_ids = combined_nodes_df[combined_nodes_df['type'] == 'output']['id'].values # Refresh list\n",
    "        \n",
    "        # Ensure all input nodes have at least one outgoing connection\n",
    "        for input_id in combined_nodes_df[combined_nodes_df['type'] == 'input']['id'].values:\n",
    "            if not any(child_edges_df['source'] == input_id):\n",
    "                hidden_nodes_in_child = combined_nodes_df[combined_nodes_df['type'] == 'hidden']\n",
    "                target_id = None\n",
    "                if not hidden_nodes_in_child.empty:\n",
    "                    target_id = hidden_nodes_in_child.sample(1).iloc[0]['id']\n",
    "                else: # Fallback to output nodes if no hidden\n",
    "                    output_nodes_in_child = combined_nodes_df[combined_nodes_df['type'] == 'output']\n",
    "                    if not output_nodes_in_child.empty:\n",
    "                        target_id = output_nodes_in_child.sample(1).iloc[0]['id']\n",
    "                \n",
    "                if target_id is not None:\n",
    "                    new_edge_id = child_edges_df['id'].max() + 1 if not child_edges_df.empty else 0\n",
    "                    new_edge_row = pd.DataFrame([{\n",
    "                        'id': new_edge_id,\n",
    "                        'source': input_id,\n",
    "                        'target': target_id,\n",
    "                        'weight': np.random.uniform(-1, 1),\n",
    "                        'enabled': True\n",
    "                    }])\n",
    "                    child_edges_df = pd.concat([child_edges_df, new_edge_row], ignore_index=True)\n",
    "                # else: No suitable target, network might be problematic, but we proceed\n",
    "        \n",
    "        # Ensure all output nodes have at least one incoming connection\n",
    "        for output_id in combined_nodes_df[combined_nodes_df['type'] == 'output']['id'].values:\n",
    "            if not any(child_edges_df['target'] == output_id):\n",
    "                hidden_nodes_in_child = combined_nodes_df[combined_nodes_df['type'] == 'hidden']\n",
    "                source_id = None\n",
    "                if not hidden_nodes_in_child.empty:\n",
    "                    source_id = hidden_nodes_in_child.sample(1).iloc[0]['id']\n",
    "                else: # Fallback to input nodes if no hidden\n",
    "                    input_nodes_in_child = combined_nodes_df[combined_nodes_df['type'] == 'input']\n",
    "                    if not input_nodes_in_child.empty:\n",
    "                        source_id = input_nodes_in_child.sample(1).iloc[0]['id']\n",
    "                \n",
    "                if source_id is not None:\n",
    "                    new_edge_id = child_edges_df['id'].max() + 1 if not child_edges_df.empty else 0\n",
    "                    new_edge_row = pd.DataFrame([{\n",
    "                        'id': new_edge_id,\n",
    "                        'source': source_id,\n",
    "                        'target': output_id,\n",
    "                        'weight': np.random.uniform(-1, 1),\n",
    "                        'enabled': True\n",
    "                    }])\n",
    "                    child_edges_df = pd.concat([child_edges_df, new_edge_row], ignore_index=True)\n",
    "                # else: No suitable source, network might be problematic, but we proceed\n",
    "\n",
    "        # Create new chromosome ID for the child\n",
    "        # Ensure child ID is unique in context of the population, if needed later for tracking\n",
    "        new_id = self.id_counter.next_id() if hasattr(self, 'id_counter') else max(parent1.id, parent2.id) + 1\n",
    "        \n",
    "        # Create and return the child chromosome\n",
    "        child = Chromosome(\n",
    "            id=new_id,\n",
    "            nodes_df=combined_nodes_df,\n",
    "            edges_df=child_edges_df,\n",
    "            generation=self.generation + 1\n",
    "        )\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def mutate(self, chromosome: Chromosome, mutation_rate: float = 0.1, weight_mutation_scale: float = 0.5, bias_mutation_scale: float = 0.2) -> Chromosome:\n",
    "        \"\"\"\n",
    "        Mutates a chromosome by altering weights, biases, and potentially its structure.\n",
    "\n",
    "        Mutation types include:\n",
    "        - Weight mutation: Random noise added to edge weights.\n",
    "        - Bias mutation: Random noise added to node biases (excluding input nodes).\n",
    "        - Edge enablement/disablement: Toggles 'enabled' status of some edges.\n",
    "        - Add new edge: Creates a new connection between existing nodes (cycle-checked).\n",
    "        - Add new hidden node: Inserts a new hidden node and connects it.\n",
    "\n",
    "        Args:\n",
    "            chromosome (Chromosome): The chromosome to be mutated.\n",
    "            mutation_rate (float, optional): Base probability for each mutation type to occur. Defaults to 0.1.\n",
    "            weight_mutation_scale (float, optional): Standard deviation for normal distribution when mutating weights. Defaults to 0.5.\n",
    "            bias_mutation_scale (float, optional): Standard deviation for normal distribution when mutating biases. Defaults to 0.2.\n",
    "\n",
    "        Returns:\n",
    "            Chromosome: The mutated chromosome.\n",
    "        \"\"\"\n",
    "        # Mutate edge weights\n",
    "        for index, edge in chromosome.edges.iterrows():\n",
    "            if random.random() < mutation_rate:\n",
    "                new_weight = edge['weight'] + np.random.normal(0, weight_mutation_scale)\n",
    "                chromosome.update_edge_weight(edge['id'], new_weight)\n",
    "        \n",
    "        # Mutate node biases (except input nodes)\n",
    "        non_input_nodes = chromosome.nodes[chromosome.nodes['type'] != 'input']\n",
    "        for index, node in non_input_nodes.iterrows():\n",
    "            if random.random() < mutation_rate:\n",
    "                new_bias = node['bias'] + np.random.normal(0, bias_mutation_scale)\n",
    "                chromosome.update_node_bias(node['id'], new_bias)\n",
    "        \n",
    "        # Structural mutation: enable/disable edges\n",
    "        if random.random() < mutation_rate * 0.5:\n",
    "            if not chromosome.edges.empty:\n",
    "                # Select a small subset of edges to potentially toggle\n",
    "                num_edges_to_toggle = max(1, int(len(chromosome.edges) * 0.1))\n",
    "                edges_to_consider = chromosome.edges.sample(min(num_edges_to_toggle, len(chromosome.edges)))\n",
    "                \n",
    "                for _, edge_to_toggle in edges_to_consider.iterrows():\n",
    "                    edge_id = edge_to_toggle['id']\n",
    "                    if edge_to_toggle['enabled']:\n",
    "                        # Simple heuristic: only disable if target node has other incoming enabled edges\n",
    "                        # This avoids completely isolating a node if it's crucial.\n",
    "                        incoming_edges_to_target = chromosome.get_edges_by_target(edge_to_toggle['target'])\n",
    "                        if len(incoming_edges_to_target[incoming_edges_to_target['enabled'] == True]) > 1:\n",
    "                            chromosome.disable_edge(edge_id)\n",
    "                    else:\n",
    "                        # Re-enable disabled edge, but check for cycle creation first\n",
    "                        if not chromosome.would_create_cycle(edge_to_toggle['source'], edge_to_toggle['target']):\n",
    "                            idx = chromosome.edges.index[chromosome.edges['id'] == edge_id].tolist()\n",
    "                            if idx:\n",
    "                                chromosome.edges.loc[idx[0], 'enabled'] = True\n",
    "        \n",
    "        # Structural mutation: add new edge\n",
    "        if random.random() < mutation_rate * 0.3:\n",
    "            node_ids = chromosome.nodes['id'].values\n",
    "            if len(node_ids) > 1:\n",
    "                for _ in range(5): # Try up to 5 times to find a valid connection\n",
    "                    source = random.choice(node_ids)\n",
    "                    target = random.choice(node_ids)\n",
    "                    \n",
    "                    # Ensure valid connection types (e.g., no output to input, no self-loops)\n",
    "                    source_type = chromosome.nodes[chromosome.nodes['id'] == source]['type'].values[0]\n",
    "                    target_type = chromosome.nodes[chromosome.nodes['id'] == target]['type'].values[0]\n",
    "                    \n",
    "                    if source_type == 'output' or target_type == 'input' or source == target:\n",
    "                        continue\n",
    "                    \n",
    "                    # Also, avoid adding an edge that already exists and is enabled\n",
    "                    existing_edge = chromosome.get_edges_between(source, target)\n",
    "                    if not existing_edge.empty and existing_edge.iloc[0]['enabled']:\n",
    "                        continue\n",
    "\n",
    "                    if chromosome.add_edge(source=source, target=target, weight=np.random.uniform(-1, 1)) is not None:\n",
    "                        break # Successfully added an edge\n",
    "        \n",
    "        # Structural mutation: add new hidden node\n",
    "        if random.random() < mutation_rate * 0.1:\n",
    "            new_node_id = chromosome.add_node(\n",
    "                node_type='hidden',\n",
    "                bias=np.random.uniform(-1, 1),\n",
    "                birth_generation=self.generation\n",
    "            )\n",
    "            \n",
    "            if new_node_id is not None:\n",
    "                # Try to connect it to the network\n",
    "                existing_nodes = chromosome.nodes[chromosome.nodes['id'] != new_node_id]['id'].values\n",
    "                \n",
    "                # Connect from a random existing node (if suitable)\n",
    "                if len(existing_nodes) > 0:\n",
    "                    for _ in range(3): # Try a few times\n",
    "                        source_id = random.choice(existing_nodes)\n",
    "                        source_type = chromosome.nodes[chromosome.nodes['id'] == source_id]['type'].values[0]\n",
    "                        if source_type != 'output':\n",
    "                            chromosome.add_edge(source=source_id, target=new_node_id, weight=np.random.uniform(-1, 1))\n",
    "                            break\n",
    "                \n",
    "                # Connect to a random existing node (if suitable)\n",
    "                if len(existing_nodes) > 0:\n",
    "                    for _ in range(3): # Try a few times\n",
    "                        target_id = random.choice(existing_nodes)\n",
    "                        target_type = chromosome.nodes[chromosome.nodes['id'] == target_id]['type'].values[0]\n",
    "                        if target_type != 'input':\n",
    "                            chromosome.add_edge(source=new_node_id, target=target_id, weight=np.random.uniform(-1, 1))\n",
    "                            break\n",
    "        \n",
    "        return chromosome\n",
    "    \n",
    "    def evolve(self, generations: int = 10, mutation_rate: float = 0.2, selection_method: str = 'tournament') -> Chromosome:\n",
    "        \"\"\"\n",
    "        Runs the main evolutionary loop for a specified number of generations.\n",
    "\n",
    "        In each generation, it performs:\n",
    "        1. Fitness evaluation of the current population.\n",
    "        2. Parent selection based on fitness.\n",
    "        3. Crossover to create offspring.\n",
    "        4. Mutation of offspring.\n",
    "        5. Replacement of the old population with the new one (plus elitism).\n",
    "\n",
    "        Args:\n",
    "            generations (int, optional): The total number of generations to run the evolution. Defaults to 10.\n",
    "            mutation_rate (float, optional): The base probability for mutation operations. Defaults to 0.2.\n",
    "            selection_method (str, optional): The method for parent selection ('tournament' or 'roulette').\n",
    "                                              Defaults to 'tournament'.\n",
    "\n",
    "        Returns:\n",
    "            Chromosome: The best chromosome found across all generations.\n",
    "        \"\"\"\n",
    "        # A simple ID counter for new chromosomes generated during evolution\n",
    "        class IDCounter:\n",
    "            def __init__(self, start_id: int):\n",
    "                self._current_id = start_id\n",
    "            def next_id(self):\n",
    "                self._current_id += 1\n",
    "                return self._current_id - 1\n",
    "        self.id_counter = IDCounter(max(c.id for c in self.population) + 1 if self.population else 0)\n",
    "\n",
    "\n",
    "        for gen in range(generations):\n",
    "            self.generation = gen # Update current generation\n",
    "            \n",
    "            # 1. Evaluate current population\n",
    "            fitness_scores = self.evaluate_population()\n",
    "            \n",
    "            # Print generation statistics\n",
    "            best_fitness_gen = fitness_scores[0][1]\n",
    "            avg_fitness_gen = sum(score for _, score in fitness_scores) / len(fitness_scores)\n",
    "            print(f\"Generation {self.generation}: Best fitness = {best_fitness_gen}, Avg fitness = {avg_fitness_gen:.2f}\")\n",
    "            \n",
    "            # 2. Select parents\n",
    "            parents = self.select_parents(fitness_scores, selection_method)\n",
    "            \n",
    "            # 3. Create new population\n",
    "            new_population: list[Chromosome] = []\n",
    "            \n",
    "            # Elitism: Keep the single best chromosome from the previous generation\n",
    "            new_population.append(fitness_scores[0][0])\n",
    "            \n",
    "            # Create offspring until the population size is reached\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1 = random.choice(parents)\n",
    "                parent2 = random.choice(parents)\n",
    "                \n",
    "                # Ensure parents are distinct if there's more than one parent available\n",
    "                attempts = 0\n",
    "                while parent2.id == parent1.id and len(parents) > 1 and attempts < 10:\n",
    "                    parent2 = random.choice(parents)\n",
    "                    attempts += 1\n",
    "                \n",
    "                # Crossover to create a child\n",
    "                child = self.crossover(parent1, parent2)\n",
    "                \n",
    "                # Mutate the child\n",
    "                child = self.mutate(child, mutation_rate)\n",
    "                \n",
    "                # Assign a unique ID to the new child\n",
    "                child.id = self.id_counter.next_id()\n",
    "                child.generation = self.generation + 1 # Child belongs to the next generation\n",
    "                \n",
    "                new_population.append(child)\n",
    "            \n",
    "            # Update population for the next generation\n",
    "            self.population = new_population\n",
    "        \n",
    "        # Return the best chromosome found throughout the entire evolutionary run\n",
    "        return self.best_chromosome\n",
    "    \n",
    "    def visualize_fitness_history(self):\n",
    "        \"\"\"\n",
    "        Visualizes the maximum and average fitness scores over generations.\n",
    "        Plots a line graph showing the evolution of fitness.\n",
    "        \"\"\"\n",
    "        if not self.fitness_history:\n",
    "            print(\"No fitness history to visualize.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.fitness_history)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['generation'], df['max_fitness'], 'b-', label='Max Fitness')\n",
    "        plt.plot(df['generation'], df['avg_fitness'], 'r-', label='Average Fitness')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.title('Fitness History Over Generations')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85726451",
   "metadata": {},
   "source": [
    "This function encapsulates the setup and execution of the entire evolutionary experiment for the CartPole task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution_experiment():\n",
    "    \"\"\"\n",
    "    Orchestrates and runs a complete evolutionary experiment for the CartPole task.\n",
    "    Initializes the evolutionary process, runs it for a specified number of generations,\n",
    "    visualizes the fitness progress, and then tests and visualizes the best performing\n",
    "    chromosome.\n",
    "    \"\"\"\n",
    "    # Define experiment parameters\n",
    "    POPULATION_SIZE = 30\n",
    "    GENERATIONS = 20\n",
    "    MUTATION_RATE = 0.2\n",
    "    \n",
    "    # Initialize the evolutionary algorithm instance\n",
    "    evolution = Evolution(\n",
    "        population_size=POPULATION_SIZE,\n",
    "        inputs=4,  # CartPole observation space has 4 values\n",
    "        outputs=1,  # CartPole action space has 2 actions (left/right), 1 output is enough (e.g., >0.5 -> right, <=0.5 -> left)\n",
    "        hidden_nodes=15, # Starting number of hidden nodes\n",
    "        connectivity_ratio=0.6 # Initial connection density\n",
    "    )\n",
    "    \n",
    "    # Run the evolutionary process\n",
    "    best_chromosome = evolution.evolve(\n",
    "        generations=GENERATIONS,\n",
    "        mutation_rate=MUTATION_RATE,\n",
    "        selection_method='tournament'\n",
    "    )\n",
    "    \n",
    "    # Visualize the fitness trends over generations\n",
    "    evolution.visualize_fitness_history()\n",
    "    \n",
    "    # Test the best chromosome found with rendering enabled to observe its behavior\n",
    "    if best_chromosome:\n",
    "        print(f\"\\nTesting best chromosome (Generation {best_chromosome.generation}, ID {best_chromosome.id})\")\n",
    "        final_fitness = evolution.evaluate_fitness(best_chromosome, render=True)\n",
    "        print(f\"Final fitness of best chromosome: {final_fitness}\")\n",
    "        \n",
    "        # Visualize the structure of the best performing neural network\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        # Ensure the visualize method does not call plt.show() if an ax is passed\n",
    "        best_chromosome.visualize() \n",
    "        plt.title(f\"Best Chromosome: Gen {best_chromosome.generation}, ID {best_chromosome.id}, Fitness {final_fitness:.2f}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No best chromosome found.\")\n",
    "    \n",
    "    return best_chromosome, evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794030b",
   "metadata": {},
   "source": [
    "### Division Demo\n",
    "\n",
    "This section specifically demonstrates the node division functionality of the Chromosome class. It creates a \"division model\" (a small neural network) and a main chromosome. The division model then dictates which hidden nodes in the main chromosome should divide, showcasing dynamic network growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072288f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Demonstrating Node Division Functionality ---\")\n",
    "\n",
    "# --- Setup the Division Model Chromosome ---\n",
    "# This Chromosome acts as a separate neural network that decides if other nodes should divide.\n",
    "# Its inputs are features of a node (age, division count, connection count, node_id).\n",
    "# Its single output (via a threshold) determines the division decision.\n",
    "division_model = Chromosome(\n",
    "    id=999,\n",
    "    inputs=4,  # [node_age, node_division_count, node_connection_count, node_id]\n",
    "    outputs=1, # [should_divide_probability]\n",
    "    hidden_nodes=5 # The Chromosome constructor expects 'hidden_nodes' as an int, not a list of layers.\n",
    ")\n",
    "\n",
    "# Randomize ALL of the weights in the division model with a wider range\n",
    "# This makes the division decision more dynamic and less predictable for testing.\n",
    "for _, edge in division_model.edges.iterrows():\n",
    "    division_model.update_edge_weight(edge['id'], np.random.uniform(-1.5, 1.5))\n",
    "\n",
    "# Set a moderate bias for the output node\n",
    "# This can influence the baseline 'propensity' to divide.\n",
    "output_nodes = division_model.get_output_nodes()\n",
    "for _, node in output_nodes.iterrows():\n",
    "    division_model.update_node_bias(node['id'], 0.2) # A slightly positive bias\n",
    "\n",
    "# --- Setup the Main Chromosome to be Evolved/Divided ---\n",
    "# This is the neural network whose structure will be dynamically modified.\n",
    "chromosome = Chromosome(\n",
    "    id=1, \n",
    "    inputs=3, \n",
    "    outputs=2, \n",
    "    hidden_nodes=10 # The Chromosome constructor expects 'hidden_nodes' as an int, not a list of layers.\n",
    ") \n",
    "\n",
    "# --- Define a Custom Bias Function for Daughter Nodes ---\n",
    "# This function determines the bias of a newly created daughter node based on its parent's bias.\n",
    "# A wider random range is used here to increase variability in daughter node biases.\n",
    "def my_bias_function(parent_bias: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the bias for a daughter node based on its parent's bias.\n",
    "    Introduces a random perturbation to the parent's bias.\n",
    "\n",
    "    Args:\n",
    "        parent_bias (float): The bias of the parent node.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated bias for the daughter node.\n",
    "    \"\"\"\n",
    "    return parent_bias + np.random.uniform(-1.0, 1.0)  # Wider range of variability\n",
    "\n",
    "# --- Run the Node Division Evaluation ---\n",
    "# This is where the division_model evaluates each hidden node in 'chromosome'\n",
    "# and performs division if the criteria are met.\n",
    "print(f\"Initial chromosome {chromosome.id} has {len(chromosome.nodes)} nodes.\")\n",
    "new_nodes = chromosome.evaluate_all_nodes_for_division(\n",
    "    division_model, \n",
    "    bias_func=my_bias_function\n",
    ")\n",
    "print(f\"After division evaluation, chromosome {chromosome.id} now has {len(chromosome.nodes)} nodes.\")\n",
    "print(f\"Newly created nodes during this round of division: {new_nodes}\")\n",
    "\n",
    "\n",
    "# --- Visualize the Network After Division ---\n",
    "# Shows the updated structure of the main chromosome.\n",
    "plt.figure(figsize=(12, 10))\n",
    "chromosome.visualize()\n",
    "plt.title(f\"Chromosome {chromosome.id} after node division (Total nodes: {len(chromosome.nodes)})\")\n",
    "plt.show()\n",
    "\n",
    "# --- Optional: Detailed Testing of Division Thresholds ---\n",
    "def test_thresholds():\n",
    "    \"\"\"\n",
    "    Performs multiple division evaluations for each hidden node to observe\n",
    "    the probabilistic nature of the division decision based on the\n",
    "    division_model and inherent randomness.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Testing division model with randomized inputs and outputs (multiple runs per node) ---\")\n",
    "    division_counts = {\"will_divide\": 0, \"wont_divide\": 0}\n",
    "    \n",
    "    # Get the IDs of hidden nodes AFTER the initial division round\n",
    "    # This ensures we test nodes that actually exist in the current chromosome state.\n",
    "    hidden_nodes_current_ids = chromosome.get_hidden_nodes()['id'].values\n",
    "    \n",
    "    if len(hidden_nodes_current_ids) == 0:\n",
    "        print(\"No hidden nodes to test for division.\")\n",
    "        return\n",
    "\n",
    "    for node_id in hidden_nodes_current_ids:\n",
    "        results_for_node = []\n",
    "        for _ in range(3):  # Test each node 3 times to see variability\n",
    "            result = chromosome.evaluate_division(node_id, division_model)\n",
    "            results_for_node.append(result)\n",
    "            \n",
    "            if result:\n",
    "                division_counts[\"will_divide\"] += 1\n",
    "            else:\n",
    "                division_counts[\"wont_divide\"] += 1\n",
    "        \n",
    "        print(f\"Node {node_id}: division results from 3 tests = {results_for_node}\")\n",
    "    \n",
    "    # Print overall statistics\n",
    "    total_tests = division_counts[\"will_divide\"] + division_counts[\"wont_divide\"]\n",
    "    divide_percentage = (division_counts[\"will_divide\"] / total_tests) * 100 if total_tests > 0 else 0\n",
    "    print(f\"\\nOverall division statistics across all test runs:\")\n",
    "    print(f\"Will divide: {division_counts['will_divide']} times ({divide_percentage:.1f}%)\")\n",
    "    print(f\"Won't divide: {division_counts['wont_divide']} times ({100-divide_percentage:.1f}%)\")\n",
    "\n",
    "# Uncomment the line below to run the detailed threshold tests\n",
    "test_thresholds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e821d6",
   "metadata": {},
   "source": [
    "This cell executes the main evolutionary algorithm, evolving a population of neural networks to solve the CartPole problem. It will print progress, visualize fitness history, and finally test and display the best-performing network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e173cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Running the Full Evolutionary Experiment (CartPole) ---\")\n",
    "best_solution, evo = run_evolution_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
